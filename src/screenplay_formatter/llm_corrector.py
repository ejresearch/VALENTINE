"""LLM-powered screenplay formatting corrector with anti-hallucination guardrails."""

import os
import json
import hashlib
import logging
from typing import List, Optional, Dict, Any, Tuple
from dataclasses import dataclass
from pydantic import BaseModel, Field
import openai

from .parser import ScreenplayElement, ElementType
from .validator import ValidationError, ErrorCode


class FixSpan(BaseModel):
    """Represents a fix span from the LLM."""
    start_line: int = Field(description="Start line index (0-based within chunk)")
    end_line: int = Field(description="End line index (inclusive)")
    original: List[str] = Field(description="Original lines")
    revised: List[str] = Field(description="Revised lines")
    issues: List[str] = Field(description="Validator error codes (e.g., E1, E3)")
    confidence: float = Field(description="Confidence score 0.0-1.0", ge=0.0, le=1.0)


class CorrectionResponse(BaseModel):
    """Response schema from LLM correction."""
    version: str = Field(description="Schema version", default="1.0")
    model: str = Field(description="Model identifier")
    fixes: List[FixSpan] = Field(description="List of corrections")
    unchanged_lines: List[int] = Field(description="Line indices left unchanged")
    notes: Optional[str] = Field(description="Brief rationale (<=200 chars)", max_length=200)


@dataclass
class ChunkContext:
    """Context for a chunk being processed."""
    start_line: int
    end_line: int
    lines: List[str]
    errors: List[ValidationError]
    elements: List[ScreenplayElement]


class LLMCorrector:
    """LLM-powered screenplay formatting corrector."""

    # Allowed tokens that can be added during correction (per style guide)
    ALLOWED_ADDED_TOKENS = {
        'INT.', 'EXT.', 'INT./EXT.', 'EXT./INT.',
        'DAY', 'NIGHT', 'DAWN', 'DUSK', 'MORNING', 'AFTERNOON', 'EVENING',
        'CONTINUOUS', 'LATER', 'MOMENTS LATER', 'SAME',
        'FADE IN:', 'FADE OUT.', 'CUT TO:', 'DISSOLVE TO:', 'SMASH TO:',
        'BEGIN MONTAGE', 'END MONTAGE', 'CHYRON:', 'TITLE:',
        'O.S.', 'V.O.', 'CONT\'D', 'THE END'
    }

    def __init__(self,
                 api_key: Optional[str] = None,
                 model: str = "gpt-4o-mini",
                 temperature: float = 0.0,
                 top_p: float = 0.1,
                 min_confidence: float = 0.8,
                 max_edit_distance: int = 8):
        """
        Initialize LLM corrector.

        Args:
            api_key: OpenAI API key (or None to use environment)
            model: OpenAI model to use
            temperature: Generation temperature (0.0 for deterministic)
            top_p: Top-p sampling parameter
            min_confidence: Minimum confidence for auto-apply
            max_edit_distance: Maximum allowed edit distance per chunk
        """
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        if not self.api_key:
            raise ValueError("OpenAI API key required. Set OPENAI_API_KEY environment variable.")

        self.model = model
        self.temperature = temperature
        self.top_p = top_p
        self.min_confidence = min_confidence
        self.max_edit_distance = max_edit_distance

        # Initialize OpenAI client
        self.client = openai.OpenAI(api_key=self.api_key)

        # Setup logging
        self.logger = logging.getLogger(__name__)

    def correct_chunk(self, chunk: ChunkContext) -> Tuple[CorrectionResponse, bool]:
        """
        Correct a single chunk using LLM.

        Args:
            chunk: Chunk context with errors and content

        Returns:
            Tuple of (correction_response, applied_successfully)
        """
        # Generate prompt
        prompt = self._generate_prompt(chunk)
        prompt_hash = hashlib.md5(prompt.encode()).hexdigest()[:8]

        self.logger.info(f"Correcting chunk lines {chunk.start_line}-{chunk.end_line}, "
                        f"errors: {[e.error_code.value for e in chunk.errors]}, "
                        f"prompt_hash: {prompt_hash}")

        try:
            # Call LLM
            response = self._call_llm(prompt)
            correction = self._parse_response(response)
            correction.model = f"{self.model}@{prompt_hash}"

            # Validate and apply corrections
            if self._validate_correction(chunk, correction):
                applied = self._apply_correction(chunk, correction)
                self.logger.info(f"Correction applied: {applied}, "
                               f"fixes: {len(correction.fixes)}, "
                               f"avg_confidence: {self._avg_confidence(correction):.2f}")
                return correction, applied
            else:
                self.logger.warning(f"Correction rejected due to validation failure")
                return correction, False

        except Exception as e:
            self.logger.error(f"LLM correction failed: {e}")
            # Return empty correction on error
            return CorrectionResponse(
                model=self.model,
                fixes=[],
                unchanged_lines=list(range(len(chunk.lines))),
                notes=f"Error: {str(e)[:100]}"
            ), False

    def _generate_prompt(self, chunk: ChunkContext) -> str:
        """Generate the correction prompt for a chunk."""
        # Extract error codes
        error_codes = [e.error_code.value for e in chunk.errors]

        # Build input text
        input_text = '\n'.join(chunk.lines)

        system_prompt = """You are a screenplay formatting corrector. You must enforce industry formatting rules without inventing story content.

ALLOWED: capitalization, whitespace/indentation normalization; moving lines between blocks; adding missing INT./EXT./TIME only when unambiguous.
FORBIDDEN: adding words/lines/characters; rewriting dialogue; creative changes.

If uncertain, output a suggestion with low confidence rather than altering the text.
Output strictly as JSON matching the provided schema. No prose."""

        user_prompt = f"""STYLE_GUIDE (per industry standards):
- Scene headings: ALL CAPS: INT./EXT. + SPECIFIC LOCATION + TIME (DAY/NIGHT/EVENING/CONTINUOUS/LATER).
- Character names: ALL CAPS, centered (~3.7" from left margin). Must be consistent throughout script.
- Dialogue: Standard capitalization, indented ~2.5" left, ~1.5" right margin. No text-speak abbreviations (idk, lol, etc).
- Parentheticals: Under character name, indented ~3.1", in parentheses (angrily), (O.S.), (V.O.). MUST be brief tone/delivery cues ONLY, not action.
- Transitions: ALL CAPS, flush right (FADE IN:, FADE OUT., CUT TO:, DISSOLVE TO:, SMASH TO:). FADE IN: is left-aligned.
- Action lines: Present tense, first character mention in ALL CAPS, short paragraphs (3-4 lines max). NO meta-comments.
- Page timing: 1 page ≈ 1 minute screen time with Courier 12pt font.
- Page breaks: Character dialogue blocks must NEVER break across pages. Keep character names with their dialogue.

COMMON ISSUES TO FIX:

1. Scene Headings:
   BAD: int.  coffee shop  –DAY     #SCENE_1
   GOOD: INT. COFFEE SHOP – DAY
   (Capitalize, standardize spacing, remove scene tags)

2. Meta-Comments:
   BAD: A BARISTA PULLS A SHOT [NOTE TO SELF: shoot wide? or ultra-tight? decide later]
   GOOD: A BARISTA pulls a shot for an empty chair.
   (Remove all [NOTE TO SELF], [TODO], [FIXME], [DECIDE], etc.)

3. Character Names:
   BAD: Jess, JESSICA, jess (inconsistent variations)
   GOOD: JESS (pick one canonical form, use consistently)
   (Unify all variations to ONE canonical ALL CAPS name)

4. Casual Text/Abbreviations:
   BAD: idk, lol, btw, omg, shh sh shhhh
   GOOD: I don't know, (laughing), by the way, oh my god, (shushing)
   (Expand abbreviations, formalize casual text)

5. Extensions:
   BAD: (o.s.), (V.O), (CONT'D)
   GOOD: (O.S.), (V.O.), (CONT'D)
   (Standardize capitalization and punctuation)

6. Parentheticals:
   BAD: (long stare . . . . too long) — This is ACTION, not tone
   GOOD: [Move to action line] She stares for a long moment.
   (Parentheticals are for brief delivery cues ONLY, not physical actions)

7. Redundancy:
   BAD: Repeated identical dialogue or action across multiple scenes
   GOOD: Flag for review - likely unintentional duplication
   (Note but don't auto-remove - may be intentional)

REMOVE THESE NON-SCREENPLAY ELEMENTS:
- File headers (PROJECT NAMES, export timestamps, version info)
- Metadata lines (Exported:, Generated:, Created:, Version:)
- Separator lines (======, ------, ******, ####)
- Scene/Act numbers that aren't part of screenplay format (ACT 1, SCENE 1)
- Date stamps and technical information
- Meta-comments: [NOTE TO SELF], [TODO], [FIXME], [DECIDE], [MAYBE]

DETECTED_ISSUES: {', '.join(error_codes)}

INPUT_CHUNK:
<<<
{input_text}
>>>

TASK:
Identify formatting issues, propose minimal fixes, and return JSON with the following schema:
{{
  "version": "1.0",
  "model": "model_name",
  "fixes": [
    {{
      "start_line": 0,
      "end_line": 0,
      "original": ["original line"],
      "revised": ["corrected line"],
      "issues": ["E1", "E2"],
      "confidence": 0.9
    }}
  ],
  "unchanged_lines": [1, 2, 3],
  "notes": "Brief explanation"
}}"""

        return user_prompt  # We'll use system message in the API call

    def _call_llm(self, prompt: str) -> str:
        """Call the OpenAI API with the prompt."""
        messages = [
            {
                "role": "system",
                "content": """You are a screenplay formatting corrector. You must enforce industry formatting rules without inventing story content.

ALLOWED: capitalization, whitespace/indentation normalization; moving lines between blocks; adding missing INT./EXT./TIME only when unambiguous.
FORBIDDEN: adding words/lines/characters; rewriting dialogue; creative changes.

If uncertain, output a suggestion with low confidence rather than altering the text.
Output strictly as JSON matching the provided schema. No prose."""
            },
            {
                "role": "user",
                "content": prompt
            }
        ]

        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=self.temperature,
            top_p=self.top_p,
            max_tokens=2000,
            response_format={"type": "json_object"},
            stop=["\n\n", "```"]
        )

        return response.choices[0].message.content

    def _parse_response(self, response_text: str) -> CorrectionResponse:
        """Parse LLM response into structured format."""
        try:
            data = json.loads(response_text)
            return CorrectionResponse(**data)
        except (json.JSONDecodeError, ValueError) as e:
            self.logger.error(f"Failed to parse LLM response: {e}")
            # Return empty response on parse failure
            return CorrectionResponse(
                model=self.model,
                fixes=[],
                unchanged_lines=[],
                notes=f"Parse error: {str(e)[:100]}"
            )

    def _validate_correction(self, chunk: ChunkContext, correction: CorrectionResponse) -> bool:
        """Validate that the correction is safe to apply."""
        for fix in correction.fixes:
            # Check confidence threshold
            if fix.confidence < self.min_confidence:
                self.logger.debug(f"Fix rejected: confidence {fix.confidence} < {self.min_confidence}")
                continue

            # Check edit distance
            edit_distance = self._calculate_edit_distance(fix.original, fix.revised)
            if edit_distance > self.max_edit_distance:
                self.logger.warning(f"Fix rejected: edit distance {edit_distance} > {self.max_edit_distance}")
                return False

            # Check for forbidden additions
            if not self._check_allowed_additions(fix.original, fix.revised):
                self.logger.warning(f"Fix rejected: contains forbidden additions")
                return False

        return True

    def _calculate_edit_distance(self, original: List[str], revised: List[str]) -> int:
        """Calculate simple edit distance between line lists."""
        # Simple token-based edit distance
        orig_tokens = set(' '.join(original).split())
        rev_tokens = set(' '.join(revised).split())

        added = rev_tokens - orig_tokens
        removed = orig_tokens - rev_tokens

        return len(added) + len(removed)

    def _check_allowed_additions(self, original: List[str], revised: List[str]) -> bool:
        """Check that only allowed tokens were added."""
        orig_text = ' '.join(original).upper()
        rev_text = ' '.join(revised).upper()

        orig_tokens = set(orig_text.split())
        rev_tokens = set(rev_text.split())

        added_tokens = rev_tokens - orig_tokens

        # Check if all added tokens are in the allowed set
        for token in added_tokens:
            if token not in self.ALLOWED_ADDED_TOKENS:
                # Allow punctuation and common formatting characters
                if token not in {'-', '–', ':', '.', '(', ')', ',', "'", '"'}:
                    self.logger.warning(f"Forbidden token added: {token}")
                    return False

        return True

    def _apply_correction(self, chunk: ChunkContext, correction: CorrectionResponse) -> bool:
        """Apply the correction to the chunk (placeholder for now)."""
        # This would integrate with the main formatter to apply changes
        # For now, just log what would be applied

        applied_fixes = 0
        for fix in correction.fixes:
            if fix.confidence >= self.min_confidence:
                self.logger.info(f"Would apply fix: lines {fix.start_line}-{fix.end_line}, "
                               f"confidence: {fix.confidence}, issues: {fix.issues}")
                applied_fixes += 1

        return applied_fixes > 0

    def _avg_confidence(self, correction: CorrectionResponse) -> float:
        """Calculate average confidence of fixes."""
        if not correction.fixes:
            return 0.0
        return sum(fix.confidence for fix in correction.fixes) / len(correction.fixes)